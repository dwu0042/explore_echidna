---
title: Examining whether the snapshot return mechanism is correct
---

```{python}
#| code-fold: true
#| code-summary: imports
import random
import numpy as np
import polars as pl
from matplotlib import pyplot as plt
import seaborn as sns
from scipy import stats
from collections import Counter

rng = np.random.default_rng()
```

We want to investigate whether the snapshot return mechanism produces the correct return time distribution.

Currently, because we do not label individuals, all individuals in the same state are treated the same.
This means that individuals in the "at home" bucket are all treated as if they have been there for some time.

We model return (and the overall return rate) in the snapshot model by balancing the number of observed departures (to home) and arrivals (from home).

We can check the concordance of this model with the temporal distribution by writing an individual based-simulation (or adapt our current simulation, where we now also  track marked individuals pretty explicitly)

We will do this by modelling a single link (single we don't care about network effects), and sending individuals through this link indirectly.


```{python}
#| code-fold: true
SNAPSHOT_DURATION = 14
times = np.arange(0, 1000)
LOGNORMAL = {'mean': np.log(120), 'sigma': 0.5}
readmission_duration = lambda size=1: rng.lognormal(LOGNORMAL['mean'], LOGNORMAL['sigma'], size=size)

log_normal_mean = np.exp(LOGNORMAL['mean'] + LOGNORMAL['sigma']**2 / 2)
log_normal_mode = np.exp(LOGNORMAL['mean'] - LOGNORMAL['sigma']**2)

base_population = 1000
base_move_out = 0.2
```

Forward simulation, generating random movement and random readmission delay times.
```{python}
#| code-fold: true
hospital_state = np.zeros_like(times)
hosp_n = base_population

movements_out = np.zeros_like(times)
movements_in = np.zeros_like(times)
movement_dist = []
for _t in times: # implictly this is also the index
    hosp_n += movements_in[_t]
    hospital_state[_t] = hosp_n
    movements_out[_t] = rng.poisson(hosp_n * base_move_out)
    hosp_n -= movements_out[_t]
    move_times = np.round(readmission_duration(movements_out[_t]), 0).astype(int) + _t
    valid_moves = move_times[move_times < np.max(times)]
    movement_dist.extend(valid_moves - _t)
    if len(valid_moves) < 1:
        continue
    move_counter = Counter(valid_moves)
    move_tos = np.array(list(move_counter.keys()))
    move_counts = np.array(list(move_counter.values()))
    movements_in[move_tos] += move_counts
```

Computing the transition matrices
```{python}
#| code-fold: true
at_home = 0
home_numbers = np.zeros_like(times)
for _t in times:
    at_home += movements_out[_t]
    home_numbers[_t] = at_home
    at_home -= movements_in[_t]

inwards_transition_prob = movements_in / home_numbers

outwards_transition_prob = movements_out / hospital_state 
```

Definitions of data structures of the "agent-based" simulation.
```{python}
#| code-fold: true
# create agents
class Agent():
    _place_map = ['hospital', 'home']
    def __init__(self):
        self.place = 0
        self.go_home_time = np.nan
        self.return_hospital_time = 0
    
    def __repr__(self) -> str:
        return f"Agent()"

    def __str__(self):
        return f"Agent [{self.place} {self.go_home_time:.0f} {self.return_hospital_time:.0f}]"

    @property
    def duration(self):
        return self.return_hospital_time - self.go_home_time
    
    def go_home(self, time):
        self.go_home_time = time
        self.place = 1
    
    def return_hospital(self, time):
        self.return_hospital_time = time
        self.place = 0

class Pool():
    # implementation == ListDict 
    # see stackoverflow 15993447
    def __init__(self):
        self.positions = {}
        self.items = []
    
    @classmethod
    def of_agents(cls, N: int):
        pool = cls()
        for _ in range(N):
            agent = Agent()
            pool.add(agent)
        return pool

    def add(self, item):
        if item in self.positions:
            return
        self.items.append(item)
        self.positions[item] = len(self.items) - 1

    def pop(self, item):
        position = self.positions.pop(item)
        last_item = self.items.pop()
        if position != len(self.items):
            self.items[position] = last_item
            self.positions[last_item] = position
        return item
    
    def extend(self, items):
        init_len = len(self.items)
        self.items.extend(items)
        new_len = len(self.items)
        for i, item in enumerate(items):
            self.positions[item] = init_len + i

    def random_choice(self):
        return random.choice(self.items)

    def random_pop(self):
        item = self.random_choice()
        return self.pop(item)

    def queue_pop(self):
        item = self.items[0]
        return self.pop(item)

    def __len__(self):
        return len(self.items)

    def __contains__(self, item):
        return item in self.positions

    def __iter__(self):
        return iter(self.items)
```


Running agent-based sim. 
```{python}
#| code-fold: true

N_AGENTS = 1000
hospital_pool = Pool.of_agents(N_AGENTS)
home_pool = Pool() 

return_delays = []
return_timings = []
pool_history = {'hospital': [], 'home': []}
movement_numbers = {'out': [], 'ret': []}
for _t in times:
    outp = outwards_transition_prob[_t]
    inwp = inwards_transition_prob[_t]

    # use implied dt=1
    n_out = np.clip(rng.poisson(outp * len(hospital_pool)), 0, len(hospital_pool))
    n_ret = rng.binomial(n=len(home_pool), p=inwp) 
    movement_numbers['out'].append(n_out)
    movement_numbers['ret'].append(n_ret)

    a_out = [hospital_pool.random_pop() for _ in range(n_out)]
    a_ret = [home_pool.random_pop() for _ in range(n_ret)]

    home_pool.extend(a_out)
    hospital_pool.extend(a_ret)

    for agent in a_out:
        agent.go_home(_t)

    for agent in a_ret:
        agent.return_hospital(_t)
        return_delays.append(agent.duration)
        return_timings.append(_t)

    pool_history['hospital'].append(len(hospital_pool))
    pool_history['home'].append(len(home_pool))
```

Plot of the observed distributions of readmission time
- simulation: from agent-based simulation
- source: from the source movement realisation
- dist: theoretical source distribution for the readmission delay
- static approximation: we approximate using the mean of the source realisation, and passing through to exponential rv dist.
```{python}
bins = np.linspace(min(times), max(times), 61)
plot_args = {'bins': bins, 'density': True, 'histtype': 'step'}
for name, arr in zip(['simulation', 'source', 'dist'], [return_delays, movement_dist, readmission_duration(100_000)]):
    plt.hist(arr, **plot_args, label=name)

tmesh = np.linspace(min(bins), max(bins), 3001)
mean_move_time = np.mean(movement_dist)
lamb = 1. /mean_move_time
plt.plot(tmesh, lamb * np.exp(-lamb * tmesh), label='static approx')

plt.legend()
```

Looking at the return time distribution over time
```{python}
#| code-fold: true
return_df = pl.from_dict({'timing': return_timings, 'delay': return_delays})
```
```{python}
sns.histplot(return_df, x='timing', y='delay', bins=61, discrete=False)
```

```{python}
sns.lineplot(return_df.group_by('timing').len(), x='timing', y='len')

plt.axvline(log_normal_mean, color='red')
plt.axvline(log_normal_mode, color='purple')

ax = plt.gca().twinx()
ax.hist(movement_dist, density=True, bins=61, histtype='step', color='red')
print(log_normal_mean, log_normal_mode)
```

We see transient behaviour as the readmission distribution kicks in, and the system trends toward the pseudo-stable state.