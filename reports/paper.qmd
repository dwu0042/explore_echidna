---
title: "Temporality of the Victorian Hospital Patient Transfer Network"
format:
  plos-pdf:
    number-sections: false
    journal:
      id: ploscompbio
    include-in-header:
      text: |
        \usepackage{setspace}
        %\doublespacing
    keep-tex: true
    fig-format: png
    fig-dpi: 300
author:
  - name: Michael J Lydeamore
    affiliations:
      - ref: ebs
      - ref: vicdh
    email: michael.lydeamore@monash.edu
    corresponding: true
  - name: David Wu
    affiliations:
      - ref: ebs
  - name: Tjibbe Donker
    affiliations:
      - ref: freiburg
  - name: Ben Cooper
    affiliations:
      - ref: oxford
  - name: Marion Easton
    affiliations:
      - ref: vicdh
  - name: Nicholas Geard
    affiliations:
      - ref: uom
  - name: Claire Gorrie
    affiliations:
      - ref: doherty
      - ref: mdu
  - name: Daneeta Hennessy
    affiliations:
      - ref: vicdh
  - name: Benjamin Howden
    affiliations:
      - ref: mdu
  - name: Anton Y Peleg
    affiliations:
      - ref: id
  - name: Charlie Higgs
    affiliations:
      - ref: mdu
  - name: Andrew Wilson
    affiliations:
      - ref: vicdh
  - name: Andrew J Stewardson
    affiliations:
      - ref: id
    
affiliations:
  - id: ebs
    name: Department of Econometrics and Business Statistics, Monash University
    city: Melbourne
    state: Victoria
    country: Australia
  - id: vicdh
    name: Victorian Department of Health, Government of Victoria
    city: Melbourne
    state: Victoria
    country: Australia
  - id: freiburg
    name: Institute for Infection Prevention and Hospital Epidemiology, University Medical Center
    state: Freiburg
    country: Germany
  - id: uom
    name: School of Computing and Information systems, University of Melbourne
    city: Melbourne
    state: Victoria
    country: Australia
  - id: mdu
    name: Microbiological Diagnostic Unit Public Health Laboratory, Department of Microbiology & Immunology, University of Melbourne, at the Peter Doherty Institute for Infection and Immunity
    city: Melbourne
    state: Victoria
    country: Australia
  - id: doherty
    name: Department of Microbiology & Immunology, University of Melbourne, at the Peter Doherty Institute for Infection and Immunity
    city: Melbourne
    state: Victoria
    country: Australia
  - id: id
    name: Department of Infectious Diseases, The Alfred and Central Clinical School, Monash University
    city: Melbourne
    state: Victoria
    country: Australia
  - id: oxford
    name: Centre for Tropical Medicine and Global Health, Nuffield Department of Medicine, University of Oxford
    state: Oxford
    country: United Kingdom


bibliography: refs.bib
crossref:
  fig-prefix: Fig
execute:
  warning: false
  error: false
---

```{python}
#| label: compute-imports
import numpy as np
from pathlib import Path
import polars as pl
from scipy import stats
from matplotlib import pyplot as plt, dates as mdates, colors as mcolors, cm
import seaborn as sns
import calendar
from itertools import accumulate
from collections import defaultdict
import datetime
import copy

root = Path("../").resolve()

sns.set_theme(
  context='paper',
  style='ticks',
  palette='colorblind',
  font='serif',
)
```

# Introduction

Antimicrobial resistance poses a great threat to human health and development. [@murray_global_2022]
Globally, it poses a large burden, operationally and economically, on hospital systems.
In Australia, we see [significant] economic burden from AMR.
this impact could become more significant if we had incursion and subsequent establishment of new [strains] of AMR. 
One X of interest, for example, is carbapenemase-producing enterobacteriacea (CPE). 
Australia has an endemic strain of CPE -- IMP4 -- but this is at a relatively low level. 
This already causes some level of burden, and introduced strains would further multiply this.

The spread of AMR in these systems has been studied by modelling the hospital system as a network or interconnected healthcare facilities. For example, [@donker_patient_2010] examines hospitals in the Netherlands to study the spread of MRSA, followed by a similar analysis of the UK hospital system in [@donker_hospital_2012]. 
Ultimately, the aim of studying these systems as networks is leveraging the network framework when designing surveillance and control protocols for emerging and recurring AMR outbreaks. This has been analysed to some extent in [@ciccolini_efficient_2014, @++needmore], but these studies neglect the temporal structure of the healthcare system, through the use of assumptions such as patients will be disease-free when they are discharged. 

The temporal structure of the healthcare systems can be considered by using temporal network models. There are existing results that show that control costs are lower in temporal networks[@li_fundamental_2017]. In the public health space, a lot of attention has been spent on patient-staff and staff-staff contacts within a hospital, for example in [@barnes_dynamic_2010; @martinet_link_2018].
Perhaps most pertinently, [@belik_leveraging_2017] explores patient referral networks using a temporal network methodology, and also consider the effect of community stays by augmenting their temporal network with additional edges corresponding to readmissions that occur within a period of $k$ days (representative of the infectious period).  


# Materials and Methods

We use admissions data sourced from the Victorian Admitted Episdoes Dataset (VAED) [@VAED_official]. This contains line-listed admissions for patients in Victoria, Australia, covering 338 healthcare facilities that vary in size, case mix and services.
the dataset contains 26,796,407 individual admissions across 5,471893 unique patients, from 1 January 2011 through to 6 December 2019 (3631 days).
Because there is no unique healthcare identifier in Victoria, Australia, linkage is performed on the VAED dataset by the Centre for Victorian Data Linkage, in order to build information on succesive admissions of patients. As a result of this linkage and hospital administrative procedures, there can be overlapping admissions, where a patient admits at a facility before being discharged at a prior facility. These overlaps are removed by constructing new admissions that are of minimal non-overlapping duration.
Some exploratory analysis of this data was done in [@lydeamore_carbapenemase-producing_2024] using a static network framework, and it characterises the structure of the healthcare system.



## Network Models

This data can be used to inform the construction of a wide variety of (weighted, directed) networks, which can, in turn, be used to construct a stochastic process model. In this study, we will use discrete time Markov chain models, where a state vector $x$ that represents the number of marked individuals at facilities $u$. Weights $w_{ij}$ of the edges $e_{ij}$ between nodes $u_i, u_j$ of the network inform the hazard function of the movement process of marked individuals between those nodes.
By default, the movement process is a Markovian process, i.e. is a Poisson random variable with hazard $\lambda_{ij}(x_i, t) = c_iw_{ij}x_i\Delta t$, where $c_i$ is a normalising constant, and $\Delta t$ is the time step.

Applying this directly to a static network of transfers between healthcare facilities, with appropriate infection dynamics, is what is done in @donker_hospital_2012, for example, and represents a model where ....
However, since individuals tend to leave the hospital system for non-negligible amoutns of time, it may be appropriate to include time spent in the community (e.g. at home) as additional nodes of the network. 
In @belik_leveraging_2017, this approach is taken with a temporal network approach in snapshot representation, where the system over a time period is represented as a series of static networks that "snapshot" the system at discrete points in time. 
Through examination of the behaviour of transfers, especially those that are indirect and cross-facilitly, we want to expand on this temporal representation, and include edges that explicityl ...

We can capture the This motivates the general representation in @fig-general-diagram, where edges from a location $u$ can go to null (discharged and never seen again), directly to some location $v$ (that could be $u$), or indirectly to $v$ via a community node $h_{uv}$. 


![Sketch of the generalised model with processes of (1) permanent discharge ($u \to \emptyset$), (2) direct transfer ($u \to v$), (3) return home ($u \to h_{uv}$), (4) readmission $h_{uv} \to v$).](diagrams/movement_general_case.pdf){#fig-general-diagram}

The governing equations can be roughly expressed as a function of the hazards of each process.

$$
\begin{aligned}
\lambda(u(s) \to \emptyset) &= \zeta_u(s)\\
\lambda(u(s) \to v(t)) &= d_{uv}(s, t)\\
\lambda(u(s) \to z_{uv}(s, t)) &= \eta_{uv}(s, t)\\
\lambda(z_{uv}(s, t) \to v(t)) &= \rho_{uv}(s, t)
\end{aligned}
$$

We note that as a consequence of the model structure, the hazards can also be interpreted as modelling the holding time an individual patient spends in each state. 

Under this general structure, we can describe four network models that capture different levels of temporal fidelity. 

:::{#fig-specific-model-diagrams layout-ncol=2 layout-nrow=2 layout-valign="bottom"}

![Naïve static](diagrams/new-networks/naive_static.pdf)

![Static](diagrams/new-networks/static.pdf)

![Snapshot](diagrams/new-networks/snapshot.pdf)

![Temporal](diagrams/new-networks/temporal.pdf)

Schematic diagrams of each type of network representation for a two-facility network. There exists a direct transfer from $u$ to $v$ and an indirect transfer from $v$ to $u$. 
:::

### Naïve Static Model

We can begin with a simple naive static model. This model will have the edge weights between healthcare facilities that represent the number of transfers from the source node to the target node over a certain period of observation time ($T_\Sigma$), regardless of how long the patient is absent from the healthcare facilities between initial discharge and subsequent readmission.

With reference to the general model above, the hazards of the  naïve static model are:

$$ d_{uv}(s,t) = d_{uv} = \frac{\sum_{s,t} w_{uv}(s,t)}{T_\Sigma N_u} $$
$$ \eta_{uv}(s,t) = \eta_{uv} = 0 $$
$$ \rho_{uv}(s,t) = \rho_{uv} = 0 $$

That is, all movements are instantaneous, and the rate of movement is the mean rate of movement over the entire observation period. This is an oversimplification of the work done in @donker, but represents a "worst" case model of temporal fidelity that can be benchmarked against.

### Improved Static Model

We can introduce the concept of "indirectness" by allowing individuals to return home, in an "improved" static model.
In this model, we choose some threshold value $\omega$ that delineates direct transfers that occur "instantaneously" and indirect transfers that require a patient to first move to an intermediary "home" state before readmitting.

In comparison to the naive model, we will have non-zero hazards $\eta$ and $\rho$:

$$d_{uv}(s,t) = d_{uv} =  \frac{\sum_{s,t: (t-s) < \omega} w_{uv}(s,t)}{T_\Sigma N_u}$$
$$\eta_{uv}(s,t) = \eta_{uv} = \frac{\sum_{s,t: (t-s) \geq \omega} w_{uv}(s,t)}{T_\Sigma N_u}$$
$$\rho_{uv}(s,t) = \rho_{uv} = \left[ \frac{\sum_{s,t: (t-s) \geq \omega} (t-s) w_{uv}(s,t)}{\sum_{s,t: (t-s) \geq \omega} w_{uv}(s,t)}  \right]^{-1}$$

Here, we model the rate of indirect transfers $\eta$ similarly to the rate of direct transfers  $d$, by counting the average rate of observed movements. For the rate of readmission, $\rho$, we use the inverse of the mean readmission duration/delay.

### Snapshot Model

Of course, as the hospital system changes over time, the rate of patient transfers, and thus the hazards represented in our model should also change.
We see evidence of this in @fig-movement-over-time where we plot the overall rates of movement in the network over time.


We approach this using static network snapshots of the hospital system over time. 

For the snapshot model, we choose a snapshot duration $\omega$. This defines the threshold duration of an indirect transfer.
This introduces an new intermediary state variable $z'$ that contains the individuals that would enter $z$ within the duration of a given snapshot $[t, t+\omega]$, so that they do not immediately readmit at their next healthcare facility.
This alters the indirect transfer processes to

$$
\begin{aligned}
\lambda(u(s) \to {z'}_{uv}(s)) &= \sum_t \eta_{uv}(s, t)\\
\lambda({z'}_{uv}(t) \to z_{uv}(t)) &= \delta(t \mod\omega)\\
\end{aligned}
$$

where $\delta(\cdot)$ is the Dirac delta function.
Alongside this, we also compute from the data, the number of patients "at home" at a given time, in order to inform the denominator for the process from $z'$ to $z$. We denote this quantity $H_{uv}(t)$
We will have that:

$$d_{uv}(s,t) = d_{uv}(s) = \frac{\sum_{t: (t-s) < \omega} w_{uv}(s,t)}{\omega N_u}$$
$$\eta_{uv}(s,t) = \eta_{uv}(s) = \frac{\sum_{t: (t-s) \geq \omega} {w_{uv}(s, t)}}{\omega N_u}$$
$$\rho_{uv}(s,t) = \rho_{uv}(t) = \frac{\sum_{s: (t-s) \geq \omega} {w_{uv}(s, t)}}{\omega H_{uv}}$$

### Temporal Model


For the temporal network, we make a choice of the time discretisation $\omega$. Events that occur within a time window $[\tau, \tau+\omega)$ are collapsed and aggregated to occur at time $\tau$. Over the observation (and simulation) period, we will have a series of time window boundaries $\{\tau_0, \tau_1, \dots\}$. We denote the smallest value in that set larger than a given time $t$ to be $\lceil{}t\rceil{}_\omega$
For the readmission process, we assume that individuals that would readmit within a given time window $[\tau, \tau+\omega)$ do so uniformly. 
This yields:

$$d_{uv}(s, t) = \frac{\sum_{t: (t-s) < \omega} w_{uv}(s, t)}{\omega N_u}$$
$$\eta_{uv}(s, t) = \frac{\sum_{t: (t-s) \geq \omega} w_{uv}(s, t)}{\omega N_u}$$
$$\rho_{uv}(s,t) = \frac{1}{\lceil{}t\rceil{}_\omega - t}$$


# Results

## Data Characterisation

The amount of patient movement in the system fluctuates temporally, as shown in @fig-movement-over-time. 
There is an increasing amount of transfers over time, and there are dips in transfers related to public holidays in the state of Victoria. This implies that we should have at least an inhomogenous Poisson process governing the rate of transfers between facilites over time. 

```{python}
#| label: compute-movement-over-time
base_date = datetime.date(2011, 1, 1)
aggregated_movement = pl.read_csv(root / "data/concordant_networks/analyses/movement_aggregated.csv")
aggregated_movement = (
  aggregated_movement
  .group_by('t')
  .agg(pl.col('w').sum())
  .sort('t')
  .with_columns(
    date=pl.lit(base_date) + pl.duration(days=pl.col('t')),
    my=pl.col('w').rolling_mean(window_size=365, center=True), # yearly ma
    mw=pl.col('w').rolling_mean(window_size=7, center=True), # weekly ma
    mm=pl.col('w').rolling_mean(window_size=28, center=True), # monthly ma
  )
)
```

```{python}
#| label: fig-movement-over-time
#| fig-cap: Number of patient transfers throughout the network increases over time. Moving averages plotted in red with periods of 1 year (main plot) and 1 week (inset). Right-hand end of data exhibits censoring behaviour, since we do not see long-terms readmissions beyond the end of the data observation period. We also observe seasonal behaviour (most visually obvious with periods of a year and a week), and consistent decreases of transfers during public holiday periods, especially at the end of the year.
fig = plt.figure()
ax = fig.add_subplot()
sns.despine(ax=ax)

nth_year = 4
x1, x2 = datetime.date(2011+nth_year-1, 12, 15), datetime.date(2011+nth_year+1, 1, 15)
y1, y2 = 12_000, 25_000
inset = ax.inset_axes(
  [0.15, 0.1, 0.7, 0.35], 
  xlim=(x1, x2), 
  ylim=(y1, y2),
  xlabel='',
  ylabel='',
  yticks=[],
  yticklabels=[],
)
for axes in (ax, inset):
  sns.lineplot(aggregated_movement, x='date', y='w', color='C0', ax=axes)

sns.lineplot(aggregated_movement, x='date', y='my', color='red', ax=ax)
sns.lineplot(aggregated_movement, x='date', y='mw', color='red', ax=inset)

ax.indicate_inset_zoom(inset, edgecolor='black')

inset.set_xlabel('')
inset.xaxis.set_major_formatter(mdates.DateFormatter('%b'))
_ = ax.set_xlabel('Date')
_ = ax.set_ylabel('Number of patient transfers')
```

Binning the length of stay and the time between sequential admissions of the same patient into 1-day bins in @fig-stay-duration and @fig-readmission-time, we can see that both quantities are power-law distributed when aggregated over the entire dataset.
Thus, a fully Markovian Poisson process on a static network is unlikely to be a good representation of the movement in the network.

```{python}
def gof_exponential(bin_edges, counts):
  bin_midpoints = (bin_edges[1:] + bin_edges[:-1]) / 2
  sample_mean = np.sum(bin_midpoints * counts) / np.sum(counts)
  lambd = 1./ sample_mean

  cumul_f = np.exp(-lambd * bin_edges)
  prop_f = -np.diff(cumul_f) * np.sum(counts)

  test_result = stats.chisquare(
    f_obs=counts,
    f_exp=prop_f,
    ddof=len(counts) - 2,
  )

  return test_result, lambd
  
```

```{python}
#| label: fig-stay-duration
#| fig-cap: Distribution of length of stays, rounded up to the nearest day.

stay_dur_df = pl.read_csv(root / "data/export/length_of_stay_binned.csv")

fig, ax = plt.subplots()
sns.scatterplot(stay_dur_df, x='bin_edge_right', y='count', ax=ax)
ax.set_xlabel('Length of Stay [days]')
ax.set_ylabel('Count')
ax.set_xscale('log')
ax.set_yscale('log')

sns.despine(ax=ax)
```

```{python}
#| label: fig-readmission-time
#| fig-cap: Distribution of empirical readmission times (time from discharge to next admission), truncated at 365 days; and best-fit exponential (via MLE).

readmission_df = pl.read_parquet(root / "data/concordant_networks/readmission_time.parquet")
readmission_df = (readmission_df
  .with_columns(
    Density = pl.col('count') / pl.col('count').sum()
  )
  .rename(
    {
      'readmission_time': 'Readmission Time [days]', 
      'count': 'Count',
    }
  )
)

fig, ax = plt.subplots()

sns.scatterplot(readmission_df, x='Readmission Time [days]', y='Density', ax=ax, label='data')
sns.despine(ax=ax)

ax.set_xscale('asinh')
_xlims = ax.set_xlim(-0.1, None)
ax.set_yscale('log')
_ylims = ax.get_ylim()

# get best fit exponential, we know that gamma = 1/mean
readmission_mean = readmission_df.select(
  pl.col('Readmission Time [days]') * pl.col('Density')
).sum().item()

gamma = 1. / readmission_mean
_xgrid = np.arange(0, 366, 1)
ax.plot(_xgrid, gamma * np.exp(-(_xgrid * gamma)), color='orange', linestyle='dashed', label='best-fit exponential')

ax.set_ylim(*_ylims)
ax.set_xlim(*_xlims)
ax.set_xticks([0, 1, 10, 100])

ax.legend()
```


## Simulation Study

Since analytical results are intractable for our more complex network models, we resort to simulation as a statistical proxy.
Movements of marked individuals are tracked for each network type, when they are seeded at each facility in the network at $t=0$. The hitting time $k_j$ to each other healthcare facililty is recorded.
We mark $N_0 = 30$ individuals at the start of each realisation; we generate $N_r=20$ realisations for each seed facility.

We plot the (empirical) cumulative distribution function of the hitting times for all pairs of seed facility and target facility in @fig-ecdf, with a zoom of the early-time distribution in @fig-ecdf-close.
We see that the naive static network model produces a hitting time distribution that has a large amount of movement of the marked individuals in a short amount of time, and that the full temporal network model produces much less movement.
This is consistent with what is expected.
We see that the 





```{python}
#| label: compute-aggregating-sim-metrics
metrics_files = {
  folder.stem: folder / "metrics_30s.parquet"
    for folder in (root / "simulations/zero_sims_resized").iterdir()
}

metrics = {
    label: pl.read_parquet(file)
    for label , file in metrics_files.items()
}

_hitting_time_columns = pl.selectors.starts_with("hitting_time_")
agg_metrics = dict()
hitting_time_dists = dict()
extent_dists = dict()

for model, df in metrics.items():
    agg_metric = (df
                .unpivot(
                    on=_hitting_time_columns,
                    index=['seed', 'extent'],
                    variable_name='target',
                    value_name='hitting_time',
                )
                .with_columns(
                    target_seed = (
                        pl.col('target')
                        .str.strip_prefix('hitting_time_')
                        .str.to_integer()
                    )
                )
                .drop('target')
                ) 
    agg_metrics[model] = agg_metric
    hitting_time_dists[model] = np.sort(agg_metric.select("hitting_time").to_series().to_numpy())
    extent_dists[model] = np.sort(agg_metric.select('extent').to_series().to_numpy())
```
```{python}
#| label: fig-ecdf
#| fig-cap: Empirical cumulative distributions of the hitting times between any pair of facilities in the network, for different network models. $N_0 =30$ individuals are seeded initially, all at one facility, and then allowed to propagate through the network.

fig = plt.figure()
ax = fig.add_subplot()
model_order = ["naive_static", "static", "snapshot", "temporal"] 
for model in model_order:
    dist = hitting_time_dists[model]
    ax.plot(dist, np.linspace(0, 1, len(dist), endpoint=False), label=model.replace('_', ' '))

ax.set_xlabel('Hitting Time (days)')
ax.set_ylabel('ECDF')

ax.legend(loc='lower right')
sns.despine(ax=ax)
```

```{python}
#| label: fig-ecdf-close
#| fig-cap: Empirical cumulative distributions of the hitting times between pairs of facilities over approxiumately the first year, for different network models.

fig, ax = plt.subplots()
for model in model_order:
    dist = hitting_time_dists[model]
    ax.plot(dist, np.linspace(0, 1, len(dist), endpoint=False), label=model.replace('_', ' '))

ax.set_xlim(-15, 350)
ax.set_ylim(-0.025, 0.15)

ax.set_xlabel('Hitting Time (days)')
ax.set_ylabel('ECDF')

ax.legend(loc='lower right')
sns.despine(ax=ax)
```

```{python}
#| label: fig-extent
#| fig-cap: Number of facilities that have had a marked individual admitted after $t=30$ days. The naïve static model overestimates the range of the spread.

max_extent = max(max(dist) for dist in extent_dists.values())
extent_bins = np.arange(max_extent+2)

# fig = plt.figure()
# ax = fig.add_subplot()
fig, axz = plt.subplots(nrows=4, sharey=True, sharex=True)
axs = axz.flatten()

model_order = ['temporal', 'snapshot', 'static', 'naive_static'] 
for ax, model in zip(axs, model_order):
  ax.hist(
    extent_dists[model],
    bins=extent_bins,
    density=True,
  )
  ax.set_ylabel(model.replace('_', '\n'))
  sns.despine(ax=ax)

_ = axs[-1].set_xlabel('Extent')
```

When comparing the aggregate number of individuals present or not present in the hospital system between models, we see some striking differences. The naïve static model has no capability for discharging individuals out of the system, so is significantly different to the other network models.
For the other models, after some burn-in period, they reach a (pseudo-)steady state. 
Notable features:
- the band at N=0 for the snapshot and temporal network models, where some individuals do not discharge - this is usually due to their seed hospital not existing until sometime much later in the simulation. This cannot be modelled with static networks, so instead in the static network, there are bands of lagging that correspond to lower global rates of discharge.
- the differing values of steady state for each model. Temporal model has the most at home, followed by the static model, and then the snapshot model.
- it seems the mechanisms for readmission in the snapshot model lead to periodic bursty readmissions, which results in a lower number of individuals at home.

```{python}
#| label: compute-load-hosp-presence
histories = {
  dir.stem: np.loadtxt(dir/"hosp_presence.csv", delimiter=',')
  for dir in (root / "simulations/zero_sims_resized/" ).iterdir()
}
```
```{python}
#| label: fig-homeprop-heatmap
#| fig-cap: Distribution of the number of individuals at home (not in the hospital system) over the first 3 years of the simulation for each model type.
 
_BASE_DATE = np.datetime64('2011-01', 'M')
_MAX_DATE = np.datetime64('2018-12', 'M')
def set_xdatelabels(hist, ax, spacing=12, dt=1.0):
    # here, we want to get succinct date formats
    # we map the times onto the timedeltas of the simulations
    N = hist.shape[1]
    emp_max_date = (np.timedelta64(int(N*dt), 'D') + _BASE_DATE).astype('datetime64[M]')
    ax_lim_date = (np.timedelta64(int(np.max(ax.get_xlim())), 'D') + _BASE_DATE).astype('datetime64[M]')
    ax_max_date = np.min([emp_max_date, _MAX_DATE, ax_lim_date])

    dates = np.arange(_BASE_DATE, ax_max_date, np.timedelta64(spacing, 'M'))

    label_pos = (dates.astype('datetime64[D]').astype('int64') - _BASE_DATE.astype('datetime64[D]').astype('int64')) / dt
    
    ax.set_xticks(label_pos, dates.astype('datetime64[Y]'), rotation=45, rotation_mode='anchor')

    return ax.get_xticks()

_DTS = defaultdict(lambda: 1.0)
_DTS['temporal'] = 0.5
def single_heatmap(model, hist, bins=(540, 31), cutoff=None, norm=None, ax=None, cbar=False):
    if ax is None:
        fig, ax = plt.subplots()
    
    if norm is None:
        norm = mcolors.Normalize()
    
    dt = _DTS[model]
    ts = (np.arange(hist.shape[1]) * dt).reshape((1, -1))
    ts_arr = np.repeat(ts, hist.shape[0], axis=0).flatten()

    if cutoff is not None:
      ts_mask = ts_arr < cutoff
      ts_arr = ts_arr[ts_mask]
      hist_arr = hist.flatten()[ts_mask]
    else:
      hist_arr = hist.flatten()

    *_, coll = ax.hist2d(
        ts_arr, 
        30 - hist_arr,
        bins=bins,
        density=True,
        norm=norm,
    )

    if cbar:
        ax.figure.colorbar(coll, ax=ax)

    return coll, ax

_ax_order = {
    'temporal': 0,
    'snapshot': 1,
    'static': 2,
    'naive_static': 3,
}
def final_heatmap(hists, norm=mcolors.PowerNorm(0.5), bins=(540, 31), cutoff=None):

    fig, axs = plt.subplots(nrows=4, figsize=[8.25, 5.25], sharex=True)
    axs_flat = axs.flatten()
    for k, h in hists.items():
        ax = axs_flat[_ax_order[k]]
        coll, _ = single_heatmap(k, h, bins=bins, cutoff=cutoff, norm=norm, ax=ax)
        norm = coll.norm
        ax.set_ylabel(k.replace('_', '\n'))
    set_xdatelabels(h, axs_flat[-1])
    fig.subplots_adjust(hspace=0.3)
    coll_norm = copy.deepcopy(coll.norm) 
    coll_norm.autoscale([0.0, bins[0]* coll.norm.vmax])
    scaled_scalar_map = cm.ScalarMappable(norm=coll_norm, cmap=coll.get_cmap())
    fig.colorbar(scaled_scalar_map, ax=axs, label='Density', extend='max')
    fig.supylabel("Number at home ($N_0=30$)")
    
    return fig, axs

_ = final_heatmap(histories, norm=mcolors.PowerNorm(0.4), bins=(313,31), cutoff=3*365)
```


# Discussion

We have investigated the effects of modelling the network representations of patient transfers between healthcare facilities in Victoria with differing levels of temporal fidelity. We see that there are qualitative behavioural differences between the movement patterns induced by these different network representations.
One unique temporal property of the networks here is that edges can connect nodes not just in space, but also in time. This leads to a reservoir of individuals of interest that exist outside of the healthcare system that will return at a later time, which leads to rich temporal dynamics. These behaviours are poorly captured by a naïve static network; including this mechanism on top of a static network representation can help significantly in moving the qualitative behaviour fo the 


# References
::: {#refs}
:::

::: {.content-visisble when-format="pdf"}
\newpage
:::


# Supplementary 

## Verification of simulation results

For any continuous-time Markov chain, we can derive the Q-matrix, which represents how ...
Importantly, we can use the forward equation to generate a viable representation of the evolution of the probability density function as a system of ODEs that scales with the number of states.

Typically, the structure of these models represents the state of the _system_; here we use the model as a representation of teh state of an _individual_. Thus, we can envision a simulation with $N_0$ initial seed individuals as being equivalent to $N_0$ independent, but identically distributed, Markov chains.
Here, then, a state maps onto a facility; for more complex models, a state may map onto either a facility, or a "home" state that could be uniquely identified by a pair of facilities.

This make computing the probability density function very computationally expensive when the number of Markov states becomes large. This is due to the fact that the ODE system will tend towards very dense matrices $P$ if the network is connected, even if $Q$ itself is sparse. This makes some representations, in particular the temporal network, completely intractable, since we would have to allocate a ${(N_f)}^2 \times {(N_T)}^2$ floating point matrix for each time step. For $N_f \sim O(10^2), N_T \sim O(10^3)$, this yields a roughly $O(10^{(10\sim 11)}$ byte (10\~100 GB) float32 matrix every time step (in memory).

Thus, we only solve this problem for the naïve static network case.
Below, we plot the analytical solution against the empirical mean hitting time of pairs that have all realisations hitting.

::: {#fig-naive-static-verification}

```{python}
#| label: compute-naive-static-verify
model = 'naive_static'
dist = hitting_time_dists['naive_static']
n_null_accept = 1 
agg_stats = (
  agg_metrics[model]
  .group_by('seed', 'target_seed')
  .agg(
    pl.col('hitting_time').mean().alias('hitting_time_mean'),
    # pl.col('extent').mean().alias('extent_mean'),
    pl.col('hitting_time').median().alias('hitting_time_median'),
    # pl.col('extent').median().alias('extent_median'),
    pl.col('hitting_time').null_count().alias('hitting_time_nulls'),
    # pl.col('extent').null_count().alias('extent_nulls'),
  )
  .with_columns(
    pl.when(pl.col('hitting_time_nulls') > n_null_accept).then(pl.lit(None)).otherwise(pl.col('hitting_time_mean')).alias('hitting_time_mean_nld'),
    pl.when(pl.col('hitting_time_nulls') > n_null_accept).then(pl.lit(None)).otherwise(pl.col('hitting_time_median')).alias('hitting_time_median_nld'),
  )
)

hit_mean = agg_stats.select('hitting_time_mean_nld').to_series().sort(nulls_last=True).to_numpy()
hit_median = agg_stats.select('hitting_time_median_nld').to_series().sort(nulls_last=True).to_numpy()

# import analytical
analytical_naive_static_soln = pl.read_csv(root / "outputs/hitting_time_analysis/numer_hitting_30s_nu_size.csv")
analytical_dist = analytical_naive_static_soln.select('hitting_time').to_series().sort(nulls_last=True).to_numpy()

N_pairs = agg_stats.shape[0]
dist_len = len(dist)
N_anal = len(analytical_dist)

fig, ax = plt.subplots()
# ax.plot(
  # dist, np.linspace(0, 1, dist_len, endpoint=False), 
  # label='empirical distribution'
# )
ax.plot(
  hit_mean, np.linspace(0, 1, N_pairs, endpoint=False),
  label='empirical mean'
)
# ax.plot(hit_median, np.linspace(0, 1, N_pairs, endpoint=False), label='median')
xlim = ax.get_xlim()
ylim = ax.get_ylim()
ax.plot(
  analytical_dist, np.linspace(0, 1, N_anal, endpoint=False),
  linestyle='dashed',
  label='analytical mean'
)
ax.set_xlim(xlim[0], max(dist) * 1.15)
# ax.set_ylim(ylim)
ax.legend()

ax.set_xlabel('time')
ax.set_ylabel('ECDF')
sns.despine(ax=ax)
```


Verification of the empirical simulation results against analytical results. We see that at early time the mean empirical and analytical expected hitting times agree, with a large right-hand censoring effect. When computing the empirical means, we allow `{python} n_null_accept` nulls (where the target facility is not hit) across all realisations.
:::

## Uniform dissapation of at-home individuals

The only process that does not have exponential waiting times is the dissapation of indivdiuals at home in the fulyl tremporal network model waiting to release into the appropriate location during their specified time bin. We need a waiting time distribution that has finite support, since all indivdiuals will return to hospital within the givne timeframe; an exponential waiting time does not have this property. We choose the uniform distribution as the most parisomonious distriubtion given the circumstance.

We know that for a random variable $t$ uniformly distributed between $[\tau, \tau+\omega]$, the pdf and survival functions are, respectively:

$$
\begin{gathered}
f(t) = \frac{1}{\omega}, \\
S(t) = \frac{(\tau+\omega) - t}{\omega},
\end{gathered}
$$

which results in a hazard function

$$
\lambda(t) = \frac{1}{(\tau + \omega) - t}.
$$

This hazard function can be simulated approximately in our DTMC framework by taking small time steps, and modelling the number of individuals $dN$ that move in a time step $dt$, where $n(t)$ is the number of inidividuals still present at time $t$ as

$$dN(t) \sim \text{Binomial}(n(t), dt\lambda(t)).$$

