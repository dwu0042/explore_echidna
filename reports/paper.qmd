---
title: "Temporality of the Victorian Hospital Patient Transfer Network"
format:
  plos-pdf:
    number-sections: false
    journal:
      id: ploscompbio
    include-in-header:
      text: |
        \usepackage{setspace}
        %\doublespacing
    keep-tex: true
    fig-format: png
    fig-dpi: 300
    cite-method: citeproc
author:
  - name: Michael J Lydeamore
    affiliations:
      - ref: ebs
      - ref: vicdh
    email: michael.lydeamore@monash.edu
    corresponding: true
  - name: David Wu
    affiliations:
      - ref: ebs
  - name: Tjibbe Donker
    affiliations:
      - ref: freiburg
  - name: Ben Cooper
    affiliations:
      - ref: oxford
  - name: Marion Easton
    affiliations:
      - ref: vicdh
  - name: Nicholas Geard
    affiliations:
      - ref: uom
  - name: Claire Gorrie
    affiliations:
      - ref: doherty
      - ref: mdu
  - name: Daneeta Hennessy
    affiliations:
      - ref: vicdh
  - name: Benjamin Howden
    affiliations:
      - ref: mdu
  - name: Anton Y Peleg
    affiliations:
      - ref: id
  - name: Charlie Higgs
    affiliations:
      - ref: mdu
  - name: Andrew Wilson
    affiliations:
      - ref: vicdh
  - name: Andrew J Stewardson
    affiliations:
      - ref: id
    
affiliations:
  - id: ebs
    name: Department of Econometrics and Business Statistics, Monash University
    city: Melbourne
    state: Victoria
    country: Australia
  - id: vicdh
    name: Victorian Department of Health, Government of Victoria
    city: Melbourne
    state: Victoria
    country: Australia
  - id: freiburg
    name: Institute for Infection Prevention and Hospital Epidemiology, University Medical Center
    state: Freiburg
    country: Germany
  - id: uom
    name: School of Computing and Information systems, University of Melbourne
    city: Melbourne
    state: Victoria
    country: Australia
  - id: mdu
    name: Microbiological Diagnostic Unit Public Health Laboratory, Department of Microbiology & Immunology, University of Melbourne, at the Peter Doherty Institute for Infection and Immunity
    city: Melbourne
    state: Victoria
    country: Australia
  - id: doherty
    name: Department of Microbiology & Immunology, University of Melbourne, at the Peter Doherty Institute for Infection and Immunity
    city: Melbourne
    state: Victoria
    country: Australia
  - id: id
    name: Department of Infectious Diseases, The Alfred and Central Clinical School, Monash University
    city: Melbourne
    state: Victoria
    country: Australia
  - id: oxford
    name: Centre for Tropical Medicine and Global Health, Nuffield Department of Medicine, University of Oxford
    state: Oxford
    country: United Kingdom


bibliography: refs.bib
crossref:
  fig-prefix: Fig
execute:
  warning: false
  error: false
---

```{python}
#| label: compute-imports
import numpy as np
from pathlib import Path
import polars as pl
from scipy import stats, special, signal, optimize
from matplotlib import pyplot as plt, dates as mdates, colors as mcolors, cm
import seaborn as sns
import calendar
from itertools import accumulate
from collections import defaultdict
import datetime
import copy

root = Path("../").resolve()

sns.set_theme(
  context='paper',
  style='ticks',
  palette='colorblind',
  font='serif',
)
```

# Introduction

Antimicrobial resistance (AMR) poses a great threat to human health and development. [@murray_global_2022]
Globally, it poses a large burden, operationally and economically, on hospital systems.
In Australia, the impact of AMR, including its economic and healthcare burden on the population, has only recently been analysed in detail [@wozniak_health_2019, @wozniak_disease_2022].
This highlights a gap in the understanding of how AMR may proliferate through the healthcare system in Australia.
One pathogen of interest, especially in the state of Victoria, is carbapenemase-producing enterobacteriacea (CPE), which is detected throughout the state, and reported through various channels to the Department of Health surveillance report. [@needref] Genomic analysis of the data indicates that suspected local acquisition is dominated by a particular gene (?), and it is of interest that its spread through the healthcare system, both actual and potential, be understood beyond reactive monitoring. [@vicorian_guideline_on_cpo_for_health_services]

The spread of AMR in healthcare systems has been studied by modelling the hospital system as a network or interconnected healthcare facilities. For example, [@donker_patient_2010] examines hospitals in the Netherlands to study the spread of MRSA, followed by a similar analysis of the UK hospital system in [@donker_hospital_2012]. 
Ultimately, the analysis of these systems as networks is leveraged when designing surveillance and control protocols for emerging and recurring AMR outbreaks. This has been done to some extent in [@ciccolini_efficient_2014, @++needmore], but these studies neglect the temporal structure of the healthcare system, through the use of assumptions such as patients will be disease-free when they are discharged. 

The temporal structure of the healthcare systems can be considered by using temporal network models. There are existing results that show that control costs are lower in temporal networks[@li_fundamental_2017]. In the public health space, a lot of attention has been spent on patient-staff and staff-staff contacts within a hospital, for example in [@barnes_dynamic_2010; @martinet_link_2018].
Perhaps most pertinently, [@belik_leveraging_2017] explores patient referral networks using a temporal network methodology, and also consider the effect of community stays by augmenting their temporal network with additional edges corresponding to readmissions that occur within a period of $k$ days (representative of the infectious period).  

In this study, we will use the Victorian healthcare system as a case study to further investigate the effects of different levels of temporal fidelity on potential models of AMR spread. To remove confounding factors, we will primarily focus on movement of individuals as carriers of AMR, and neglect the disease transmission component of the analysis.

# Materials and Methods

We use admissions data sourced from the Victorian Admitted Episdoes Dataset (VAED) [@VAED_official]. This contains line-listed admissions for patients in Victoria, Australia, covering 338 healthcare facilities that vary in size, case mix and services.
the dataset contains 26,796,407 individual admissions across 5,471893 unique patients, from 1 January 2011 through to 6 December 2019 (3631 days).
Some exploratory analysis of this data was done in [@lydeamore_carbapenemase-producing_2024] using a static network framework, and it characterises the structure of the healthcare system.
Overlapping admissions for a patient are resolved by deferring to the patient's most recent admission event, and the method is described in detail in the Appendix, and is used in [@donker_patient_2010,@nekkab_assessing_2020]. 

As stated above, existing literature does examine patient transfer networks using network analysis methods. These encompass a large range of dynamics and temporal fidelity of movement.
Here, we will consider a number of different models of movement at various levels of temporal fidelity. In general, we will decompose the model of patient movement as in @fig-general-diagram, where a patient is discharged at location $u$ at time $s$, to either never readmit (move to $\emptyset$), directly transfer to location $v$ at time $s$, or return home $h_{uv}$ and admit at location $v$ at some later time $t$. This dynamic is replicated at each pair of locations $(u, v)$, and potentially over all pairs of times $(s, t)$.
The hazards for these processes are used to define discrete-time stochastic processes that can be analysed, and will be simulated, in order to understand the dynamics of the movement models.
These can be captured in @eq-general-model-transitions:

$$
\begin{aligned}
\lambda(u(s) \to \emptyset) &= \zeta_u(s)\\
\lambda(u(s) \to v(s)) &= d_{uv}(s)\\
\lambda(u(s) \to h_{uv}(s, t)) &= \eta_{uv}(s, t)\\
\lambda(h_{uv}(s, t) \to v(t)) &= \rho_{uv}(s, t)
\end{aligned}
$$ {#eq-general-model-transitions}


Under this general structure, we can describe four network models that capture different levels of temporal fidelity. 

:::{#fig-specific-model-diagrams layout-ncol=2 layout-nrow=2 layout-valign="bottom"}

![Naïve static](diagrams/new-networks/naive_static.pdf)

![Static](diagrams/new-networks/static.pdf)

![Snapshot](diagrams/new-networks/snapshot.pdf)

![Temporal](diagrams/new-networks/temporal.pdf)

Schematic diagrams of each type of network representation for a two-facility network. There exists a direct transfer from $u$ to $v$ and an indirect transfer from $v$ to $u$. 
:::

### Naïve Static Model

We can begin with a simple naive static model. This model will have the edge weights between healthcare facilities that represent the number of transfers from the source node to the target node over a certain period of observation time ($T_\Sigma$), regardless of how long the patient is absent from the healthcare facilities between initial discharge and subsequent readmission.

With reference to the general model above, the hazards of the  naïve static model are:

$$ d_{uv}(s) = d_{uv} = \frac{\sum_{s,t} w_{uv}(s,t)}{T_\Sigma N_u} $$
$$ \eta_{uv}(s,t) = \eta_{uv} = 0 $$
$$ \rho_{uv}(s,t) = \rho_{uv} = 0 $$

That is, all movements are instantaneous, and the rate of movement is the mean rate of movement over the entire observation period. This is an oversimplification of the work done in @donker_hospital_2012, but represents a "worst" case model of temporal fidelity that can be benchmarked against.

### Improved Static Model

We can introduce the concept of "indirectness" by allowing individuals to return home, in an "improved" static model.
In this model, we choose some threshold value $\omega$ that delineates direct transfers that occur "instantaneously" and indirect transfers that require a patient to first move to an intermediary "home" state before readmitting.

In comparison to the naive model, we will have non-zero hazards $\eta$ and $\rho$:

$$d_{uv}(s) = d_{uv} =  \frac{\sum_{s,t: (t-s) < \omega} w_{uv}(s,t)}{T_\Sigma N_u}$$
$$\eta_{uv}(s,t) = \eta_{uv} = \frac{\sum_{s,t: (t-s) \geq \omega} w_{uv}(s,t)}{T_\Sigma N_u}$$
$$\rho_{uv}(s,t) = \rho_{uv} = \left[ \frac{\sum_{s,t: (t-s) \geq \omega} (t-s) w_{uv}(s,t)}{\sum_{s,t: (t-s) \geq \omega} w_{uv}(s,t)}  \right]^{-1}$$

Here, we model the rate of indirect transfers $\eta$ similarly to the rate of direct transfers  $d$, by counting the average rate of observed movements. For the rate of readmission, $\rho$, we use the inverse of the mean readmission duration/delay.

### Snapshot Model

Of course, as the hospital system changes over time, the rate of patient transfers, and thus the hazards represented in our model should also change.
We see evidence of this in @fig-movement-over-time where we plot the overall rates of movement in the network over time.

We approach this using static network snapshots of the hospital system over time. 

For the snapshot model, we choose a snapshot duration $\omega$. This defines the threshold duration of an indirect transfer.
This introduces an new intermediary state variable $z'$ that contains the individuals that would enter $z$ within the duration of a given snapshot $[t, t+\omega]$, so that they do not immediately readmit at their next healthcare facility.
This alters the indirect transfer processes to

$$
\begin{aligned}
\lambda(u(s) \to {z'}_{uv}(s)) &= \sum_t \eta_{uv}(s, t)\\
\lambda({z'}_{uv}(t) \to z_{uv}(t)) &= \delta(t \mod\omega)\\
\end{aligned}
$$

where $\delta(\cdot)$ is the Dirac delta function.
Alongside this, we also compute from the data, the number of patients "at home" at a given time, in order to inform the denominator for the process from $z'$ to $z$. We denote this quantity $H_{uv}(t)$
We will have that:

$$d_{uv}(s) = \frac{\sum_{t: (t-s) < \omega} w_{uv}(s,t)}{\omega N_u}$$
$$\eta_{uv}(s,t) = \eta_{uv}(s) = \frac{\sum_{t: (t-s) \geq \omega} {w_{uv}(s, t)}}{\omega N_u}$$
$$\rho_{uv}(s,t) = \rho_{uv}(t) = \frac{\sum_{s: (t-s) \geq \omega} {w_{uv}(s, t)}}{\omega H_{uv}}$$

### Temporal Model


For the temporal network, we make a choice of the time discretisation $\omega$. Events that occur within a time window $[\tau, \tau+\omega)$ are collapsed and aggregated to occur at time $\tau$. Over the observation (and simulation) period, we will have a series of time window boundaries $\{\tau_0, \tau_1, \dots\}$. We denote the smallest value in that set larger than a given time $t$ to be $\lceil{}t\rceil{}_\omega$
For the readmission process, we assume that individuals that would readmit within a given time window $[\tau, \tau+\omega)$ do so uniformly. 
This yields:

$$d_{uv}(s) = \frac{\sum_{t: (t-s) < \omega} w_{uv}(s, t)}{\omega N_u}$$
$$\eta_{uv}(s, t) = \frac{\sum_{t: (t-s) \geq \omega} w_{uv}(s, t)}{\omega N_u}$$
$$\rho_{uv}(s,t) = \frac{1}{\lceil{}t\rceil{}_\omega - t}$$


# Results

## Data Characterisation

The amount of patient movement in the system fluctuates temporally, as shown in @fig-movement-over-time. 
There is an increasing amount of transfers over time, and there are dips in transfers related to public holidays in the state of Victoria. This implies that we should have at least an inhomogenous Poisson process governing the rate of transfers between facilites over time. 

```{python}
#| label: compute-movement-over-time
base_date = datetime.date(2011, 1, 1)
aggregated_movement = pl.read_csv(root / "data/concordant_networks/analyses/movement_aggregated.csv")
aggregated_movement = (
  aggregated_movement
  .group_by('t')
  .agg(pl.col('w').sum())
  .sort('t')
  .with_columns(
    date=pl.lit(base_date) + pl.duration(days=pl.col('t')),
    my=pl.col('w').rolling_mean(window_size=365, center=True), # yearly ma
    mw=pl.col('w').rolling_mean(window_size=7, center=True), # weekly ma
    mm=pl.col('w').rolling_mean(window_size=28, center=True), # monthly ma
  )
)
```

```{python}
#| label: fig-movement-over-time
#| fig-cap: Number of patient transfers throughout the network increases over time. Moving averages plotted in red with periods of 1 year (main plot) and 1 week (inset). Right-hand end of data exhibits censoring behaviour, since we do not see long-terms readmissions beyond the end of the data observation period. We also observe seasonal behaviour (most visually obvious with periods of a year and a week), and consistent decreases of transfers during public holiday periods, especially at the end of the year.
fig = plt.figure()
ax = fig.add_subplot()
sns.despine(ax=ax)

nth_year = 4
x1, x2 = datetime.date(2011+nth_year-1, 12, 15), datetime.date(2011+nth_year+1, 1, 15)
y1, y2 = 12_000, 25_000
inset = ax.inset_axes(
  [0.15, 0.1, 0.7, 0.35], 
  xlim=(x1, x2), 
  ylim=(y1, y2),
  xlabel='',
  ylabel='',
  yticks=[],
  yticklabels=[],
)
for axes in (ax, inset):
  sns.lineplot(aggregated_movement, x='date', y='w', color='C0', ax=axes)

sns.lineplot(aggregated_movement, x='date', y='my', color='red', ax=ax)
sns.lineplot(aggregated_movement, x='date', y='mw', color='red', ax=inset)

ax.indicate_inset_zoom(inset, edgecolor='black')

inset.set_xlabel('')
inset.xaxis.set_major_formatter(mdates.DateFormatter('%b'))
_ = ax.set_xlabel('Date')
_ = ax.set_ylabel('Number of patient transfers')
```

Binning the length of stay and the time between sequential admissions of the same patient into 1-day bins in @fig-stay-duration and @fig-readmission-time, we can see that both quantities are power-law distributed, or at least heavy-tailed, when aggregated over the entire dataset.
Thus, a fully Markovian Poisson process on a static network is unlikely to be a good representation of the movement in the network.


```{python}
#| label: compute-fitting-util-fns

def pull_xfx(df, make_midpoint=True, left="bin_edge_right", right="bin_edge_right", quantity='bin_midpoint', count="count"):
  if make_midpoint:
    xfx_df = df.with_columns(bin_midpoint=(pl.col(left)+pl.col(right))/2)
  else:
    xfx_df = df
  x_arr = xfx_df.select(quantity).to_series().to_numpy()
  y_arr = xfx_df.select(count).to_series().to_numpy()
  return x_arr, y_arr
  
def scaled_N(x, fx, xmin):
  mask = x > xmin
  return np.sum(fx[mask])

# power law via pareto MLE
def estimate_alpha(x, fx, xmin, discr_corr=0.5):
  mask = x > xmin
  relative_x = np.log(x[mask] / (xmin-discr_corr))
  sum_relx = fx[mask] * relative_x
  return 1 + np.sum(fx[mask]) / np.sum(sum_relx)

def power_law_density_fn(xs, alpha, xmin, N=1):
  return N * (xs ** (-alpha) / special.zeta(alpha, xmin))

# power law graphical method
def power_law_fit_graphical(x, fx, xmin):
  mask = (fx > 0) & (x > xmin)
  coefs = stats.linregress(np.log(x[mask]), np.log(fx[mask]))
  return coefs.slope, np.exp(coefs.intercept)

# expon fitting utils
def estimate_gamma(x, fx):
  mean_val = np.sum(x*fx) / np.sum(fx)
  return 1./ mean_val

def expon_density_fn(xs, gamma, N=1):
  return N * gamma * np.exp(-gamma * xs)
```

```{python}
#| label: fig-stay-duration
#| fig-cap: Distribution of length of stays, rounded up to the nearest day.

stay_dur_df = pl.read_csv(root / "data/export/length_of_stay_binned.csv")

stay_dur_xmin = 28
stay_dur_xfx = pull_xfx(stay_dur_df)
stay_dur_expon_gamma = estimate_gamma(*stay_dur_xfx)
stay_dur_pow_alpha = estimate_alpha(*stay_dur_xfx, xmin=stay_dur_xmin)

stay_dur_xgrid = np.linspace(1, 3000, 3000)

fig, ax = plt.subplots()
sns.scatterplot(stay_dur_df, x='bin_edge_right', y='count', linewidth=0, ax=ax)
ax.set_xscale('log')
ax.set_yscale('log')
ylim_ = ax.get_ylim()
ax.plot(
  stay_dur_xgrid, 
  expon_density_fn(
    stay_dur_xgrid, 
    stay_dur_expon_gamma, 
    N=stay_dur_xfx[1].sum()
  ),
  color='C1', 
  label='best-fit exponential',
)
ax.plot(
  stay_dur_xgrid,
  power_law_density_fn(
    stay_dur_xgrid, 
    stay_dur_pow_alpha,
    xmin = stay_dur_xmin,
    N=scaled_N(*stay_dur_xfx, xmin=stay_dur_xmin),
  ),
  color='C2',
  label='power law fit'
)
ax.set_xlabel('Length of Stay [days]')
ax.set_ylabel('Count')
ax.set_ylim(ylim_)
ax.legend()

sns.despine(ax=ax)
```

```{python}
#| label: fig-readmission-time
#| fig-cap: Distribution of empirical readmission times (time from discharge to next admission), truncated at 365 days; and best-fit exponential (via MLE).

readmission_df = pl.read_parquet(root / "data/concordant_networks/readmission_time.parquet")
readmission_df = (readmission_df
  .with_columns(
    Density = pl.col('count') / pl.col('count').sum()
  )
  .rename(
    {
      'readmission_time': 'Readmission Time [days]', 
      'count': 'Count',
    }
  )
)

fig, ax = plt.subplots()

sns.scatterplot(readmission_df, x='Readmission Time [days]', y='Density', ax=ax, label='data')
sns.despine(ax=ax)

ax.set_xscale('asinh')
_xlims = ax.set_xlim(-0.1, None)
ax.set_yscale('log')
_ylims = ax.get_ylim()

# get best fit exponential, we know that gamma = 1/mean
readmission_mean = readmission_df.select(
  pl.col('Readmission Time [days]') * pl.col('Density')
).sum().item()

gamma = 1. / readmission_mean
_xgrid = np.linspace(0.0, 366, 10_000)
ax.plot(_xgrid, gamma * np.exp(-(_xgrid * gamma)), color='orange', linestyle='dashed', label='best-fit exponential')

readmits_xfx = pull_xfx(readmission_df, make_midpoint=False, quantity='Readmission Time [days]', count='Density')
alpha, cees = power_law_fit_graphical(*readmits_xfx, xmin=30)
ax.plot(_xgrid, cees * _xgrid ** alpha, color='green', label='power law fit')

ax.set_ylim(*_ylims)
ax.set_xlim(*_xlims)
ax.set_xticks([0, 1, 10, 100])

ax.legend()
```


## Simulation Study

Since analytical results are intractable for our more complex network models, we resort to simulation as a statistical proxy.
Movements of marked individuals are tracked for each network type, when they are seeded at each facility in the network at $t=0$. The hitting time $k_j$ to each other healthcare facililty is recorded.
We mark $N_0 = 30$ individuals at the start of each realisation; we generate $N_r=20$ realisations for each seed facility.

We plot the (empirical) cumulative distribution function of the hitting times for all pairs of seed facility and target facility in @fig-ecdf, with a zoom of the early-time distribution in @fig-ecdf-close.
We see that the naive static network model produces a hitting time distribution that has a large amount of movement of the marked individuals in a short amount of time, and that the full temporal network model produces much less movement.
This is consistent with what is expected.
We see that the 





```{python}
#| label: compute-aggregating-sim-metrics
metrics_files = {
  folder.stem: folder / "metrics_30s.parquet"
    for folder in (root / "simulations/zero_sims_resized").iterdir()
}

metrics = {
    label: pl.read_parquet(file)
    for label , file in metrics_files.items()
}

_hitting_time_columns = pl.selectors.starts_with("hitting_time_")
agg_metrics = dict()
hitting_time_dists = dict()
extent_dists = dict()

for model, df in metrics.items():
    agg_metric = (df
                .unpivot(
                    on=_hitting_time_columns,
                    index=['seed', 'extent'],
                    variable_name='target',
                    value_name='hitting_time',
                )
                .with_columns(
                    target_seed = (
                        pl.col('target')
                        .str.strip_prefix('hitting_time_')
                        .str.to_integer()
                    )
                )
                .drop('target')
                ) 
    agg_metrics[model] = agg_metric
    hitting_time_dists[model] = np.sort(agg_metric.select("hitting_time").to_series().to_numpy())
    extent_dists[model] = np.sort(agg_metric.select('extent').to_series().to_numpy())
```
```{python}
#| label: fig-ecdf
#| fig-cap: Empirical cumulative distributions of the hitting times between any pair of facilities in the network, for different network models. $N_0 =30$ individuals are seeded initially, all at one facility, and then allowed to propagate through the network.

fig = plt.figure()
ax = fig.add_subplot()
model_order = ["naive_static", "static", "snapshot", "temporal"] 
for model in model_order:
    dist = hitting_time_dists[model]
    ax.plot(dist, np.linspace(0, 1, len(dist), endpoint=False), label=model.replace('_', ' '))

ax.set_xlabel('Hitting Time (days)')
ax.set_ylabel('ECDF')

ax.legend(loc='lower right')
sns.despine(ax=ax)
```

```{python}
#| label: fig-ecdf-close
#| fig-cap: Empirical cumulative distributions of the hitting times between pairs of facilities over approxiumately the first year, for different network models.

fig, ax = plt.subplots()
for model in model_order:
    dist = hitting_time_dists[model]
    ax.plot(dist, np.linspace(0, 1, len(dist), endpoint=False), label=model.replace('_', ' '))

ax.set_xlim(-15, 350)
ax.set_ylim(-0.025, 0.15)

ax.set_xlabel('Hitting Time (days)')
ax.set_ylabel('ECDF')

ax.legend(loc='lower right')
sns.despine(ax=ax)
```

```{python}
#| label: fig-extent
#| fig-cap: Number of facilities that have had a marked individual admitted after $t=30$ days. The naïve static model overestimates the range of the spread.

max_extent = max(max(dist) for dist in extent_dists.values())
extent_bins = np.arange(max_extent+2)

# fig = plt.figure()
# ax = fig.add_subplot()
fig, axz = plt.subplots(nrows=4, sharey=True, sharex=True)
axs = axz.flatten()

model_order = ['temporal', 'snapshot', 'static', 'naive_static'] 
for ax, model in zip(axs, model_order):
  ax.hist(
    extent_dists[model],
    bins=extent_bins,
    density=True,
  )
  ax.set_ylabel(model.replace('_', '\n'))
  sns.despine(ax=ax)

_ = axs[-1].set_xlabel('Extent')
```

When comparing the aggregate number of individuals present or not present in the hospital system between models, we see some striking differences. The naïve static model has no capability for discharging individuals out of the system, so is significantly different to the other network models.
For the other models, after some burn-in period, they reach a (pseudo-)steady state. 
Notable features:
- the band at N=0 for the snapshot and temporal network models, where some individuals do not discharge - this is usually due to their seed hospital not existing until sometime much later in the simulation. This cannot be modelled with static networks, so instead in the static network, there are bands of lagging that correspond to lower global rates of discharge.
- the differing values of steady state for each model. Temporal model has the most at home, followed by the static model, and then the snapshot model.
- it seems the mechanisms for readmission in the snapshot model lead to periodic bursty readmissions, which results in a lower number of individuals at home.

```{python}
#| label: compute-load-hosp-presence
histories = {
  dir.stem: np.loadtxt(dir/"hosp_presence.csv", delimiter=',')
  for dir in (root / "simulations/zero_sims_resized/" ).iterdir()
}
```
```{python}
#| label: fig-homeprop-heatmap
#| fig-cap: Distribution of the number of individuals at home (not in the hospital system) over the first 3 years of the simulation for each model type.
 
_BASE_DATE = np.datetime64('2011-01', 'M')
_MAX_DATE = np.datetime64('2018-12', 'M')
def set_xdatelabels(hist, ax, spacing=12, dt=1.0):
    # here, we want to get succinct date formats
    # we map the times onto the timedeltas of the simulations
    N = hist.shape[1]
    emp_max_date = (np.timedelta64(int(N*dt), 'D') + _BASE_DATE).astype('datetime64[M]')
    ax_lim_date = (np.timedelta64(int(np.max(ax.get_xlim())), 'D') + _BASE_DATE).astype('datetime64[M]')
    ax_max_date = np.min([emp_max_date, _MAX_DATE, ax_lim_date])

    dates = np.arange(_BASE_DATE, ax_max_date, np.timedelta64(spacing, 'M'))

    label_pos = (dates.astype('datetime64[D]').astype('int64') - _BASE_DATE.astype('datetime64[D]').astype('int64')) / dt
    
    ax.set_xticks(label_pos, dates.astype('datetime64[Y]'), rotation=45, rotation_mode='anchor')

    return ax.get_xticks()

_DTS = defaultdict(lambda: 1.0)
_DTS['temporal'] = 0.5
def single_heatmap(model, hist, bins=(540, 31), cutoff=None, norm=None, ax=None, cbar=False):
    if ax is None:
        fig, ax = plt.subplots()
    
    if norm is None:
        norm = mcolors.Normalize()
    
    dt = _DTS[model]
    ts = (np.arange(hist.shape[1]) * dt).reshape((1, -1))
    ts_arr = np.repeat(ts, hist.shape[0], axis=0).flatten()

    if cutoff is not None:
      ts_mask = ts_arr < cutoff
      ts_arr = ts_arr[ts_mask]
      hist_arr = hist.flatten()[ts_mask]
    else:
      hist_arr = hist.flatten()

    *_, coll = ax.hist2d(
        ts_arr, 
        30 - hist_arr,
        bins=bins,
        density=True,
        norm=norm,
    )

    if cbar:
        ax.figure.colorbar(coll, ax=ax)

    return coll, ax

_ax_order = {
    'temporal': 0,
    'snapshot': 1,
    'static': 2,
    'naive_static': 3,
}
def final_heatmap(hists, norm=mcolors.PowerNorm(0.5), bins=(540, 31), cutoff=None):

    fig, axs = plt.subplots(nrows=4, figsize=[8.25, 5.25], sharex=True)
    axs_flat = axs.flatten()
    for k, h in hists.items():
        ax = axs_flat[_ax_order[k]]
        coll, _ = single_heatmap(k, h, bins=bins, cutoff=cutoff, norm=norm, ax=ax)
        norm = coll.norm
        ax.set_ylabel(k.replace('_', '\n'))
    set_xdatelabels(h, axs_flat[-1])
    fig.subplots_adjust(hspace=0.3)
    coll_norm = copy.deepcopy(coll.norm) 
    coll_norm.autoscale([0.0, bins[0]* coll.norm.vmax])
    scaled_scalar_map = cm.ScalarMappable(norm=coll_norm, cmap=coll.get_cmap())
    fig.colorbar(scaled_scalar_map, ax=axs, label='Density', extend='max')
    fig.supylabel("Number at home ($N_0=30$)")
    
    return fig, axs

_ = final_heatmap(histories, norm=mcolors.PowerNorm(0.4), bins=(313,31), cutoff=3*365)
```


# Discussion

We have investigated the effects of modelling the network representations of patient transfers between healthcare facilities in Victoria with differing levels of temporal fidelity. We see that there are qualitative behavioural differences between the movement patterns induced by these different network representations.
One unique temporal property of the networks here is that edges can connect nodes not just in space, but also in time. This leads to a reservoir of individuals of interest that exist outside of the healthcare system that will return at a later time, which leads to rich temporal dynamics. 
At a high-level, a model with better temporal fidelity suggests a much less severe outbreak -- the number of facilities that could be affected by colonised in a given time period after initial detection is lower than suggested by a more static model. 
However, this slowdown is caused by a large "reservoir" that exists "outside" of the healthcare system, and is thus much more difficult to detect. 
These behaviours are poorly captured by a naïve static network; including this mechanism on top of a static network representation can help significantly in moving the qualitative behaviour of the hitting time distribution towards the one produced by the temporal network representation.

There are some clear avenues of further investigation from the current study.
One of these is the addition of disease transmission dynamics. We chose to neglect these mechanisms due to the complexity of defining and characterising the manner of transmission within a facility -- and this can have confounding effects on the interpretation of observed results. It is believed that CPE, for example, is transmitted through the environment, but commentary on reservoirs and control strategies in the clinical literature [@kotsanas_down_2013,@de_geyter_sink_2017,@meschiari_five-component_2021] suggests that there is no well agreed-on conceptual model of the mechanisms of transmission.

Another research avenue is comparing the results against an agent-based simulation. In the current study, we have used a discrete time stepping scheme in order to allow for some non-Markovian behaviour while still retaining a reasonable simulation time. This results in the loss of the abililty to "track" individual patients through the system. In order to recover this ability, and impose more complex rules about individual patient pathways, an agent-based simulation would be required. These higher-order pathways have been shown to cause significant difference in ward-to-ward movement within hospital facilities in [@myall_network_2021]; similar results would be expected for transfers between facilities. Of course, allowing this would require an order of magnitude more computational power, memory, and time.


# References
::: {#refs}
:::

::: {.content-visisble when-format="pdf"}
\newpage
:::


# Supplementary 

## Removal of admission overlaps

Due to a variety of reasons ranging from the lack of a unique patient identifier and administrative data entry errors, there are instances of overlapping admissions for a single patient.
In these cases, we resolve these overlaps by deferring to the admission event that had 

## Verification of simulation results

For any continuous-time Markov chain, we can derive the Q-matrix, which represents how ...
Importantly, we can use the forward equation to generate a viable representation of the evolution of the probability density function as a system of ODEs that scales with the number of states.

Typically, the structure of these models represents the state of the _system_; here we use the model as a representation of teh state of an _individual_. Thus, we can envision a simulation with $N_0$ initial seed individuals as being equivalent to $N_0$ independent, but identically distributed, Markov chains.
Here, then, a state maps onto a facility; for more complex models, a state may map onto either a facility, or a "home" state that could be uniquely identified by a pair of facilities.

This make computing the probability density function very computationally expensive when the number of Markov states becomes large. This is due to the fact that the ODE system will tend towards very dense matrices $P$ if the network is connected, even if $Q$ itself is sparse. This makes some representations, in particular the temporal network, completely intractable, since we would have to allocate a ${(N_f)}^2 \times {(N_T)}^2$ floating point matrix for each time step. For $N_f \sim O(10^2), N_T \sim O(10^3)$, this yields a roughly $O(10^{(10\sim 11)})$ byte (10\~100 GB) float32 matrix every time step (in memory).

Thus, we only solve this problem for the naïve static network case.
Below, we plot the analytical solution against the empirical mean hitting time of pairs that have all realisations hitting.

::: {#fig-naive-static-verification}

```{python}
#| label: compute-naive-static-verify
model = 'naive_static'
dist = hitting_time_dists['naive_static']
n_null_accept = 1 
agg_stats = (
  agg_metrics[model]
  .group_by('seed', 'target_seed')
  .agg(
    pl.col('hitting_time').mean().alias('hitting_time_mean'),
    # pl.col('extent').mean().alias('extent_mean'),
    pl.col('hitting_time').median().alias('hitting_time_median'),
    # pl.col('extent').median().alias('extent_median'),
    pl.col('hitting_time').null_count().alias('hitting_time_nulls'),
    # pl.col('extent').null_count().alias('extent_nulls'),
  )
  .with_columns(
    pl.when(pl.col('hitting_time_nulls') > n_null_accept).then(pl.lit(None)).otherwise(pl.col('hitting_time_mean')).alias('hitting_time_mean_nld'),
    pl.when(pl.col('hitting_time_nulls') > n_null_accept).then(pl.lit(None)).otherwise(pl.col('hitting_time_median')).alias('hitting_time_median_nld'),
  )
)

hit_mean = agg_stats.select('hitting_time_mean_nld').to_series().sort(nulls_last=True).to_numpy()
hit_median = agg_stats.select('hitting_time_median_nld').to_series().sort(nulls_last=True).to_numpy()

# import analytical
analytical_naive_static_soln = pl.read_csv(root / "outputs/hitting_time_analysis/numer_hitting_30s_nu_size.csv")
analytical_dist = analytical_naive_static_soln.select('hitting_time').to_series().sort(nulls_last=True).to_numpy()

N_pairs = agg_stats.shape[0]
dist_len = len(dist)
N_anal = len(analytical_dist)

fig, ax = plt.subplots()
# ax.plot(
  # dist, np.linspace(0, 1, dist_len, endpoint=False), 
  # label='empirical distribution'
# )
ax.plot(
  hit_mean, np.linspace(0, 1, N_pairs, endpoint=False),
  label='empirical mean'
)
# ax.plot(hit_median, np.linspace(0, 1, N_pairs, endpoint=False), label='median')
xlim = ax.get_xlim()
ylim = ax.get_ylim()
ax.plot(
  analytical_dist, np.linspace(0, 1, N_anal, endpoint=False),
  linestyle='dashed',
  label='analytical mean'
)
ax.set_xlim(xlim[0], max(dist) * 1.15)
# ax.set_ylim(ylim)
ax.legend()

ax.set_xlabel('time')
ax.set_ylabel('ECDF')
sns.despine(ax=ax)
```


Verification of the empirical simulation results against analytical results. We see that at early time the mean empirical and analytical expected hitting times agree, with a large right-hand censoring effect. When computing the empirical means, we allow `{python} n_null_accept` nulls (where the target facility is not hit) across all realisations.
:::

## Uniform dissapation of at-home individuals

The only process that does not have exponential waiting times is the dissapation of indivdiuals at home in the fulyl tremporal network model waiting to release into the appropriate location during their specified time bin. We need a waiting time distribution that has finite support, since all indivdiuals will return to hospital within the givne timeframe; an exponential waiting time does not have this property. We choose the uniform distribution as the most parisomonious distriubtion given the circumstance.

We know that for a random variable $t$ uniformly distributed between $[\tau, \tau+\omega]$, the pdf and survival functions are, respectively:

$$
\begin{gathered}
f(t) = \frac{1}{\omega}, \\
S(t) = \frac{(\tau+\omega) - t}{\omega},
\end{gathered}
$$

which results in a hazard function

$$
\lambda(t) = \frac{1}{(\tau + \omega) - t}.
$$

This hazard function can be simulated approximately in our DTMC framework by taking small time steps, and modelling the number of individuals $dN$ that move in a time step $dt$, where $n(t)$ is the number of inidividuals still present at time $t$ as

$$dN(t) \sim \text{Binomial}(n(t), dt\lambda(t)).$$

## Fitting power-law distributions for binned data

Due to the underlying data being identiiable health information, we extract binned data for analysing the distributions of patient admission durations and inter-admission duration. We also right truncate the inter-admission duration [check]

For the distribution of patient stay durations, we use the method from @clauset_power-law_2009, where the probability distribution function is given by

$$
f(x) = \frac{\alpha - 1}{x_{\textrm{min}}} \left(\frac{x}{x_{\textrm{min}}}\right)^\alpha,
$$

where $\alpha and x_{\textrm{min}}$ are distributional parameters. For a given $x_\textrm{min}$, the MLE for $\alpha$ is recovered as

$$
\hat{\alpha}(x_\text{min}) = 1 + n \left[\sum_{i=1}^{n} \log\left(\frac{x_i}{x_\textrm{min}}\right) \right].
$$

$x_\text{min}$ is estimated by a grid search, and looking the region where the corresponding $\hat{\alpha}\text{s}$ are stable. We note that it is probably more appropriate to seek a piecewise power law fit, but we do not use these power law fits directly in our simulation models.

```{python}
#| label: fig-stay-dur-xmin-gridsearch
#| fig-cap: Stay duration grid search 
stay_dur_df = pl.read_csv(root / "data/export/length_of_stay_binned.csv")

stay_dur_xfx = pull_xfx(stay_dur_df)

xmin_arr = np.arange(1, 400)
alpha_hats = [estimate_alpha(*stay_dur_xfx, xmin=xmin) for xmin in xmin_arr]
Ncounts = [scaled_N(*stay_dur_xfx, xmin=xmin) for xmin in xmin_arr]

fig, axs = plt.subplots(ncols=2, figsize=(10, 4))
axz = axs.flatten()

axz[1].plot(xmin_arr, alpha_hats)
axz[1].set_xlabel(r'$x_\text{min}$')
axz[1].set_ylabel(r'$\hat\alpha$')

axz[0].scatter(*stay_dur_xfx, alpha=0.4, color='C0', zorder=999, linewidth=0)
axz[0].set_xscale('log')
axz[0].set_yscale('log')
axz[0].set_xlabel('Stay Duration [Days]')
axz[0].set_ylabel('Count')
ylim_ = axz[0].get_ylim()

xgrid = np.linspace(0.5, 2500, 10_000)
xgrid_norm = mcolors.Normalize(vmin=-100, vmax=max(xmin_arr))
xgrid_clrs = cm.ScalarMappable(cmap=cm.YlOrRd, norm=xgrid_norm)
for xmin, alpha, NN in zip(xmin_arr, alpha_hats, Ncounts):
  axz[0].plot(
    xgrid, 
    power_law_density_fn(xgrid, alpha, xmin, N=NN),
    lw=0.75,
    color=xgrid_clrs.to_rgba(xmin),
  )
axz[0].set_ylim(ylim_)
clbr = fig.colorbar(xgrid_clrs, ax=axz[0])
clbr.ax.set_ylim((0, None))
```

For readmission, preliminary linear regression on log-log shows that we have $\alpha < 1$, so we cannot use the result from @clauset_power-law_2009. Instead, we inspect the behaviour of a the linear regressop on log-log as a function of a lower threshold $x_\text{min}$.
The probability density function will follow:
$$ 
f(x) = c x^\alpha, \qquad x_\text{min} \leq x \leq x_\text{max}
$$

```{python}
#| label: fig-readmit-gridsearch 
#| fig-cap: Readmission time grid search 
readmit_df = pl.read_parquet(root / "data/concordant_networks/readmission_time.parquet")

readmit_xfx = pull_xfx(readmit_df, make_midpoint=False, quantity='readmission_time')

r_xmin_arr = np.arange(1, 200)
power_law_fits = [power_law_fit_graphical(*readmit_xfx, xmin=xm) for xm in r_xmin_arr]
pl_alphas, pl_icpts = zip(*power_law_fits)

fig, axs = plt.subplot_mosaic(
  [
    ['datafit', 'alpha'], 
    ['datafit', 'coeficpt'],
  ], 
  figsize=[10, 4],
)


axs['alpha'].plot(r_xmin_arr, pl_alphas)
# axs['alpha'].set_xlabel(r'$x_\text{min}$')
axs['alpha'].set_ylabel(r'$\hat\alpha$')

axs['coeficpt'].plot(r_xmin_arr, pl_icpts)
axs['coeficpt'].set_xlabel(r'$x_\text{min}$')
axs['coeficpt'].set_ylabel(r'$\hat{c}$')

axs['datafit'].scatter(*readmit_xfx, alpha=0.4, color='C0', zorder=997, linewidth=0)
axs['datafit'].set_xscale('log')
axs['datafit'].set_yscale('log')
axs['datafit'].set_xlabel('Readmission Duration [Days]')
axs['datafit'].set_ylabel('Count')
ylim_ = axs['datafit'].get_ylim()

r_xgrid = np.linspace(0.5, 370, 10_000)
r_xmin_norm = mcolors.Normalize(vmin=-50, vmax=max(r_xmin_arr))
r_xmin_clrs = cm.ScalarMappable(cmap=cm.YlOrRd, norm=r_xmin_norm)
for xmin, (alpha, icpt) in zip(r_xmin_arr, power_law_fits):
  axs['datafit'].plot(
    r_xgrid, 
    icpt * r_xgrid ** alpha,
    lw=0.75,
    color=r_xmin_clrs.to_rgba(xmin),
  )
axs['datafit'].set_ylim(ylim_)
clbr = fig.colorbar(r_xmin_clrs, ax=axs['datafit'])
clbr.ax.set_ylim((0, None))
```
